\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[preprint]{neurips_2024}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{pgfplots}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{adjustbox}
\usepackage{graphicx}
\usepackage{titlesec}
\usepackage{subcaption}
\usepackage[colorinlistoftodos,bordercolor=orange,backgroundcolor=orange!20,linecolor=orange,textsize=scriptsize]{todonotes}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{proposition}[theorem]{Proposition}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Rmax}{\mathbb{R}_{\max}}
\newcommand{\trop}{\mathbb{T}}
\newcommand{\T}{\mathbb{T}}

\title{Efficient Tropical SVMs via Mean-Payoff Games}

\author{
  Xavier Allamigeon \\
  Inria and CMAP \\
  École polytechnique \\
  Palaiseau, France \\
  \And
  Samuel Boïté \\
  Inria and CMAP \\
  École polytechnique \\
  Palaiseau, France \\
  \And
  Stéphane Gaubert \\
  Inria and CMAP \\
  École polytechnique \\
  Palaiseau, France \\
  \And
  Théo Molfessis \\
  Inria and CMAP \\
  École polytechnique \\
  Palaiseau, France \\
}

\begin{document}

\maketitle
\begin{abstract}
   In 2006, Gärtner and Jaggi introduced a tropical analogue of support vector machines, using a single tropical hyperplane in dimension $n$ to separate $n$ classes of points. Efficiently computing tropical separators has remained an open problem.
   We introduce an algorithm for Tropical Support Vector Machines that overcomes the combinatorial explosion of previous approaches.
   Our main result shows that the spectral radius of a specially constructed Shapley operator fully characterizes separability and margin, and gives a sense for data overlap in the non-separable case.
   This provides a reduction to mean-payoff games, a well studied class of problems in algorithmic game theory.
   This approach enables computing of an optimal separating hyperplane via scalable iterative algorithms -- with a complexity linear in the size of the data set and pseudo-polynomial in the desired precision.
   Finally, we combine tropical classifiers with linear feature maps to construct piecewise-linear classifiers.
\end{abstract}

\section{Introduction}\label{sec:intro}

Classification is a fundamental task in machine learning, and Support Vector Machines (SVMs) have been a cornerstone method for decades. Traditional SVMs create decision boundaries using affine hyperplanes, which provide maximum-margin separation with strong generalization guarantees \cite{vapnik1999}. However, these linear boundaries become limiting when faced with complex, nonlinear data patterns, typically requiring kernel methods or feature engineering \cite{scholkopf2002}.

\paragraph{Motivation: Beyond Linear Boundaries.} We build on max-plus algebra, a framework where standard addition becomes the maximum operation, and multiplication becomes addition \cite{maclagan2015}. This leads to different geometric structures with attractive properties for machine learning: (1) instead of creating binary partitions, tropical hyperplanes divide space into multiple sectors, making them naturally suited for multi-class problems; (2) their piecewise-linear nature captures more complex patterns while maintaining interpretability; (3) the resulting decision boundaries coincide with those created by modern deep learning models with ReLU activations~\cite{zhang2018}. These properties provide richer, yet interpretable, decision boundaries that can capture nonlinear patterns in data while maintaining computational tractability \cite{maragos2021}.

Tropical geometry has emerged as a powerful tool for modeling piecewise-linear phenomena in machine learning. Together with polyhedral geometry,
it has been used to bound the number of linearity regions ot functions realized by these networks~\cite{zhang2018,montufar}.
It has been successfully applied to linear regression \cite{maragos2020,akian2020}, principal component analysis \cite{yoshida2019}, neural network analysis \cite{maragos2021}, and clustering \cite{monod2022}.

\paragraph{Previous Work on Tropical SVMs.} Gärtner and Jaggi \cite{gartner2008} introduced tropical SVMs using linear programming formulations. Their work introduced an elegant geometric approach to multiclass problems, since a single tropical hyperplane in dimension $d$ partitions the space in $d$ regions.
Despite these theoretical benefits, their method required exploring all possible sector assignment combinations, leadi
ng to exponential worst-case complexity. This computational barrier has limited practical applications.
Tang et al.~\cite{tang2020} and Monot et al~\cite{monod2022} later developed specialized algorithms for binary classification cases where data points from the same category stay in the same sector, showing promising results in computational biology for analyzing evolutionary trees.\todo{quote lavishly yoshida}

\paragraph{Background on mean‐payoff games.}
Our approach uses concepts from game theory--specifically, Shapley operators arising in zero-sum dynamic games.
Shapley introduced an ``operator approach'' for discounted stochastic games~\cite{shapley1953}, and Gillette later formulated the undiscounted, infinite-horizon variant now known as mean-payoff games~\cite{gillette1957}.
The Shapley operators we employ encode the one-step payoffs and transitions in such games, whose objective is the long-run average reward per time unit~\cite{zwick1996}. 
The spectral properties of these operators have been extensively studied to characterize fixed points and convergence in nonlinear systems~\cite{kolokoltsov1997,gaubert2004}.
In particular, the spectral radius of a Shapley operator equals the game's value.
Mean-payoff games lie in NP $\cap$ coNP, but no polynomial-time algorithm is known.
Nonetheless, large instances can be solved efficiently by iterative schemes such as relative Krasnoselskii-Mann iteration, which require $O(L/\varepsilon^2)$ operator evaluations, which is \emph{linear} in input size $L$ for a precision $\varepsilon$.

\paragraph{Contributions.} We develop a new approach to tropical classification using mean-payoff games,
overcoming the computational limitations of previous approaches:

\begin{enumerate}
    \item We establish a direct connection between separability and the spectral radius $\rho(T)$ of a Shapley operator constructed from class-specific projections.
    
    \item We prove that when data are separable, the optimal margin equals $-\rho(T)$. Moreover, in the binary non-separable case, $\rho(T)$ quantifies exactly how much the data points would need to be perturbed to achieve separability.
    
    \item We develop an algorithm based on mean-payoff games and Krasnoselskii--Mann iteration that computes the optimal classifier in a time that is linear in the input size.
    
    \item We extend our framework to tropical polynomial classifiers, enabling more expressive piecewise linear decision boundaries (see Figure~\ref{fig:tropical_poly}) while preserving theoretical margin guarantees.
\end{enumerate}

This work makes tropical SVMs tractable for real-world applications, enabling natural multi-class classification, and opening new directions for piecewise-linear methods that balance expressivity, interpretability, and computational efficiency.

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.58\textwidth}
        \centering
        \resizebox{\textwidth}{!}{\clipbox{0.15\width{} 0.30\height{} 0.15\width{} 0.30\height{}}{\input{figures/moons.pgf}}}
        \label{fig:tropical_poly}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.38\textwidth}
        \centering
        \resizebox{\textwidth}{!}{\clipbox{0.20\width{} 0.20\height{} 0.20\width{} 0.20\height{}}{\input{figures/example.pgf}}}
        \label{fig:hyperplane_example}
    \end{subfigure}
    \caption{Left: Visualization of a degree-2 polynomial classifier on the moons dataset. Each region corresponds to a sector where a specific affine combination of the features dominates, creating an interpretable piecewise-linear decision boundary. Right: Tropical hyperplane representation in projective space, with the constant vector (1,1,1) projected to the origin. Each sector corresponds to a coordinate that dominates relative to the apex.}
    \label{fig:combined}
\end{figure}

The remainder of the paper is organized as follows. Section~\ref{sec:prelim} introduces the essential concepts from tropical geometry. Section~\ref{sec:spectral} presents our spectral framework and main theoretical results, showing how separability connects to spectral properties. Section~\ref{sec:algorithm} details our algorithm and implementation, explaining how we achieve pseudo-polynomial complexity. Section~\ref{sec:polynomials} extends the framework to polynomials for more expressive decision boundaries. Section~\ref{sec:maslov} explores connections with classical SVMs, and Section~\ref{sec:discussion} discusses limitations and future directions. The code to reproduce our figures and experiments is available at \url{https://github.com/samuelbx/tropical-svm}.

\section{Tropical Geometry Preliminaries}\label{sec:prelim}

We now introduce the key concepts from tropical geometry that form the foundation of our approach.

\paragraph{The Max-Plus Semiring.}
The tropical (or max-plus) semiring $\trop = \R \cup \{-\infty\}$ replaces traditional arithmetic operations with:
\begin{align}
x \oplus y &= \max(x,y) \quad \text{(tropical addition)} \\
x \odot y &= x + y \quad \text{(tropical multiplication)}
\end{align}

These operations may seem strange at first, but they naturally model systems where we care about ``bottlenecks'' or ``critical paths.'' For example, in project planning, if task A takes $x$ days and task B takes $y$ days, the project completion time depends on the maximum ($x \oplus y$) of these durations if tasks are parallel, and their sum ($x \odot y$) if sequential.

\paragraph{Projective Space.}  
The tropical projective space identifies points that differ by adding the same constant to all coordinates. Formally, it's the quotient of $\trop^d \setminus \{(-\infty,\dots,-\infty)\}$ by the equivalence relation $x \sim y$ if $x = y + c \cdot \mathbf{1}$ for some constant $c$. In practice, we embed data from $\R^d$ into the projective space via:
\[
x=(x_1,\dots,x_d)\mapsto (x_1,\dots,x_d,-(x_1+\cdots+x_d))
\]

This transformation makes our classifier invariant to shifts—adding the same constant to all features doesn't change the classification. It's similar to how projective geometry in computer vision makes analysis invariant to camera distance.

\paragraph{Hyperplanes and Sectors.}
A tropical hyperplane with apex $a \in \trop^d$ is defined as:
\begin{align}
\mathcal{H}_a = \left\{ x \in \trop^d : \text{the maximum of }(x_i + a_i)\text{ over $1\leq i\leq d$ is attained at least twice} \right\}.
\end{align}

This hyperplane divides the space into at most $d$ sectors. The $i$-th sector contains points where the maximum of $x + a$ occurs at the $i$-th coordinate:
\begin{align}
S_i(a) = \left\{x \in \trop^d : i \in \underset{j}{\arg\max} (x_j + a_j)\right\}.
\end{align}

Unlike classical hyperplanes that create two half-spaces, tropical hyperplanes create multiple sectors—one for each dimension. They naturally support multi-class classification, where we can assign different sectors to different classes.

\paragraph{Hilbert Seminorm.}
The Hilbert seminorm measures the spread of coordinates:
\begin{align}
\|x\|_H = \max_i x_i - \min_i x_i
\end{align}

This induces a projective distance $d_H(x,y) = \|x - y\|_H$ that remains invariant to adding the same constant to all coordinates \cite{cohen2004}. We use this distance to define margins in tropical classification. For classification, it tells us how confidently a point belongs to its assigned sector rather than another sector.

\paragraph{Convexity and Projections.}
A set $C \subset \trop^d$ is a \emph{tropical convex cone} if for all $x,y$ in $C$ and coefficients $\lambda,\mu$ in $\trop$,
the point $(\lambda \odot x) \oplus (\mu \odot y)$ is also in $C$ \cite{cohen2004,develin2004}.
The tropical convex hull of points $\{x_1,\ldots,x_p\}$ is defined as:
\begin{align}
  \text{cone}_{\max}(X) = \left\{\bigoplus_{i=1}^p \lambda_i \odot x_i : \lambda_i \in \trop\} \right\}
\end{align}

The tropical projection $P_X(y)$ of a point $y$ onto this convex hull is:
\begin{align}
P_X(y) = \max\{z \in \text{cone}_{\max}(X) : z \leq y\}
\end{align}
\todo[inline,color=red!30]{SG. This is the projection on a cone, not on a convex set, perhaps we need to speak only of cones (modulo passing to the projective space), then this is ok. For a convex set, the max may be taken over a nonempty set}
Tropical convexity generalizes the idea of conventional convexity to the max-plus setting. A conical tropical convex hull contains all tropical linear combinations of vectors. Moreover, the projection finds a ``closest'' point in the conical convex hull~\cite{AGNS10}.
\todo{SG: cite also Chepoi}

These projections will play a central role in our classification framework. We will use them to build class-specific operators that characterize the separability of data.

\section{Spectral Framework for Tropical SVMs}\label{sec:spectral}

Having established the basics of tropical geometry, we now develop our spectral approach to classification. The key insight is connecting the separability of data classes to the spectral properties of a specially constructed operator.

\paragraph{Shapley Operators and Their Spectral Theory.}
A Shapley operator $T: \R^d \to \R^d$ satisfies two fundamental properties \cite{kolokoltsov1992}:
\begin{enumerate}
    \item \textit{Monotonicity:} If $x \leq y$ coordinatewise, then $T(x) \leq T(y)$ coordinatewise
    \item \textit{Additive homogeneity:} For any constant $\alpha \in \R$, $T(\alpha + x) = \alpha + T(x)$,
      where $\alpha +x$ denotes the vector obtained by adding $\alpha$ to every entry of $x$.
\end{enumerate}
It admits a unique continuous extension $\T^d\to \T^d$, also denoted by $T$ \cite{akian_correspondence_2011}. Then, the spectral radius of $T$ is defined as:
\begin{align}
\rho(T) = \max\left\{\lambda \in \R : \exists u \neq -\infty \text{ with } T(u) = \lambda + u\right\},
\end{align}
where $-\infty\in \T^n$ denotes the all $-\infty$ vector -- the ``zero'' vector in max-plus algebra.
The maximum is always achieved.

Equivalently, $\rho(T)$ is the smallest value of $\lambda\in \R$ for which there exists a vector $u\in\R^d$
satisfying $T(u) \leq \lambda + u$ \cite{nussbaum1986,AGGut10,akiangaubertqisaadi}.

\paragraph{Constructing the Classification Operator.}
Consider a classification problem with $K$ classes, each represented by a set of points $X^1,\dots,X^K \subset \trop^d$. We define an operator $T^k$ for each class $k$ by taking the diagonal-free variant of the tropical projection onto the convex hull of points in that class:
\[
T^k(x) = P_{X^k}^{\text{DF}}(x)
\]
This diagonal-free variant is defined in Section~\ref{sec:algorithm}.

We then combine these operators into a single classification operator $T$ defined coordinatewise as:
\[
T(x)_i = \operatorname{\max}_2\{T^1(x)_i, \dots, T^K(x)_i\}\label{eq:single_operator}
\]
where $\operatorname{\max}_2$ denotes the second-largest value among the outputs. For binary classification ($K=2$), this simplifies to $T(x)=\min\{T^1(x), T^2(x)\}$.

\paragraph{Main Theorem: Spectral Separability.}
Our central result establishes the connection between separability and the spectral radius:
\begin{theorem}[Spectral Separability Criterion]\label{thm:spectral_separability}
Let $X^1,\ldots,X^K \subset \trop^d$ be labeled point sets and let $T$ be the classification operator defined above. Then:

(1) \textit{Separability Criterion:} The data are separable by a hyperplane if and only if $\rho(T) < 0$.

(2) \textit{Margin Optimality:} In the separable case, the maximum achievable margin equals $-\rho(T)$.

(3) \textit{Soft-Margin Interpretation:} For binary classification with overlapping data, $\rho(T)$ is positive and quantifies the minimal perturbation needed to achieve separability.

Moreover, both $\rho(T)$ and an associated apex vector $a$ satisfying $T(a) = \rho(T)+a$ can be computed in pseudo-polynomial time using mean-payoff game algorithms (see Section~\ref{sec:algorithm}).
\end{theorem}
A complete proof is provided in Appendix~\ref{appendix:proofs}, where we will see that some of these results remain with more general assumptions.
It is organized as follows: first, Lemma~\ref{lemma:hyperplane_to_operator} states that for tropical projections (or their diagonal-free counterpart), $-\rho(T)$ is a lower bound on the margin.
Then, Lemma~\ref{lemma:operator_to_hyperplane} gives a construction for a separating hyperplane of margin $-\rho(T)$ in the separable case. Finally, Lemma~\ref{lemma:perturbation} handles the binary overlapping case.

\paragraph{Benefits of the Spectral Approach.} 
Our framework advances the tropical SVM foundation established by Gärtner and Jaggi \cite{gartner2008}. Their work showed that tropical SVM could be formulated as finding a point of maximum margin within a tropical polytope defined by sector constraints, but required exhaustive exploration of sector assignments—leading to exponential complexity.

In contrast, our spectral characterization offers a complete theoretical understanding of when data are tropically separable, an exact formula for the optimal margin, an efficient algorithm to find the optimal classifier without combinatorial exploration and a natural interpretation for non-separable cases.

\paragraph{Limitations.} 
The primary limitation of our spectral approach is its sensitivity to outliers. Since convex hulls encompass all points in each class, a single misplaced point can significantly alter the classification boundary and potentially render previously separable data inseparable.

Additionally, because our method is formulated as a spectral criterion rather than an optimization problem, it's challenging to incorporate relaxation mechanisms that would handle misclassified points in a controlled way. Traditional SVMs use slack variables to allow soft margins and tolerate some misclassifications, but our current approach doesn't have a direct equivalent. This suggests an important direction for future research.

\section{Algorithm and Implementation}\label{sec:algorithm}

Having established the theoretical foundation, we now present our algorithm for tropical SVM based on the spectral criterion. The key insight is that we can compute the spectral radius and optimal hyperplane efficiently without exploring all possible sector assignments.

\paragraph{Efficient Computation of Projections.}
\label{subsec:computing_projections}
The first step is to compute the projections efficiently. The projection $P_X(y)$ of a point $y$ onto the tropical convex hull of a set $X \subset \trop^d$ can be computed using:
\[
P_X(y)_i = \max_{1 \leq j \leq p} \left\{X_{ij} + \min_{1 \leq k \leq d} \left(-X_{kj} + y_k\right)\right\}
\]
where $p$ is the number of points in $X$ and $X_{ij}$ is the $i$-th coordinate of the $j$-th point.

This formulation can be viewed as a mean-payoff game \cite{akian2020} and computed in $\mathcal{O}(pd)$ time—linear in both the number of points and dimensions.
There are two players, ``Max'' and ``Min'' (the maximizer
and the minimizer), who alternate their actions. Starting on node
$i$, Player Max chooses to move to node $j$, and receives $X_{ij}$
from Player Min. Similarly, Player Min in turn chooses a node $k$
and has to pay $-X_{kj}$ to Player Max.

This enables us to define diagonal-free ``projections'' \cite{gaubert2011}:
\begin{align}
P_X^{\text{DF}}(y)_i = \max_{1 \leq j \leq p} \left\{X_{ij} + \min_{k \neq i} (-X_{kj} + y_k)\right\}.
\end{align}
In this modified game, the opponent is prevented from replying eye-for-an-eye.

\paragraph{Computing the Spectral Radius with Krasnoselskii-Mann Iterations.}
\label{subsec:spectral_computation}
To compute the spectral radius $\rho(T)$ and a corresponding eigenvector $a$, we apply a Krasnoselskii-Mann iteration scheme \cite{baillonbruck},
outlined in Algorithm~\ref{alg:km_iteration}.

\begin{algorithm}
\caption{Krasnoselskii--Mann Iteration for Tropical SVM}\label{alg:km_iteration}
\begin{algorithmic}[1]
\STATE \textbf{Input:} Shapley operator $T$, convergence threshold $\varepsilon > 0$
\STATE \textbf{Initialize:} $x^{(0)} \in \R^d$ (typically set to $\mathbf{1}_d$), $\lambda^{(0)} = 0$
\FOR{$k = 0, 1, 2, \ldots$ until convergence}
  \STATE $z^{(k+1)} \leftarrow \frac{1}{2}\bigl(x^{(k)} + T(x^{(k)})\bigr)$
  \STATE $x^{(k+1)} \leftarrow z^{(k+1)} - \max\bigl(z^{(k+1)}\bigr)\,\mathbf{1}_d$ 
  \STATE $\lambda^{(k+1)} \leftarrow 2\max\bigl(z^{(k+1)}\bigr) - \max\bigl(x^{(k)}\bigr)$
  \IF{$\left\|T(x^{(k)})-x^{(k)}\right\|_H\leq \varepsilon$}
    \STATE \textbf{break}
  \ENDIF
\ENDFOR
\STATE \textbf{Return:} $\rho(T) \approx \lambda^{(\text{final})}$, $a \approx x^{(\text{final})} - \frac{1}{d}\sum_{i=1}^d x_i^{(\text{final})} \cdot \mathbf{1}_d$
\end{algorithmic}
\end{algorithm}
Recent results by Allamigeon et al. \cite{allamigeon2025} show that this iteration achieves an $\varepsilon$-approximation in $O(1/\varepsilon^2)$ iterations. By avoiding the combinatorial exploration of sector assignments, our method runs in pseudo-polynomial time—specifically $O\bigl(\frac{nd}{\varepsilon^2}\bigr)$ for $n$ data points in $d$ dimensions.
\todo{[Samuel] true source?}

\paragraph{The Complete Tropical SVM Algorithm.}\label{subsec:complete_algorithm}
Algorithm~\ref{alg:tropical_svm} presents our complete procedure for tropical SVM classification.

\begin{algorithm}
\caption{Tropical SVM}\label{alg:tropical_svm}
\begin{algorithmic}[1]
\STATE \textbf{Input:} Labeled point sets $X^1,\dots,X^K \subset \trop^d$
\STATE \textbf{Construct Operators:}
  \STATE \quad For each class $k$, compute the tropical projection operator $T^k(x) = P_{X^k}(x)$
  \STATE \quad Combine via $T(x)_i = \operatorname{\max}_2\{T^1(x)_i, \dots, T^K(x)_i\}$ for each coordinate $i$
\STATE \textbf{Compute Eigenpair:}
  \STATE \quad Run Krasnoselskii-Mann iterations (Algorithm \ref{alg:km_iteration}) to obtain $\rho(T)$ and apex $a$
\STATE \textbf{Assign Sectors to Classes:}
  \IF{$\rho(T) < 0$ \COMMENT{Separable case}}
    \STATE Assign coordinate $i$ to class $k$ if $T^k(a)_i > \rho(T) + a_i$
  \ELSE
    \STATE Use a heuristic (e.g., majority vote) for non-separable data
  \ENDIF
\STATE \textbf{Output:} Apex $a$, margin $-\rho(T)$ (if separable), and sector assignments for classification
\end{algorithmic}
\end{algorithm}

\paragraph{Empirical Performance Analysis.}
We validated the computational complexity of our algorithm through empirical testing (detailed in Appendix~\ref{appendix:empirical}). Our implementation achieves tractable performance on standard benchmark datasets, with performance scaling linearly with both dataset size and feature dimension as predicted by our theoretical analysis.

For the first time, we demonstrate that tropical SVMs can be practically computed with pseudo-polynomial guarantees, removing the exponential barrier that limited previous approaches. While specialized classical SVM libraries remain faster on conventional tasks, our approach enables new applications where piecewise-linear decision boundaries offer advantages.

Future optimizations could include kernel methods, sparse representations for large datasets, and parallel implementations to further improve performance on high-dimensional problems.

\section{Tropical Polynomials for Enhanced Expressivity}\label{sec:polynomials}

While hyperplanes provide effective classification boundaries, we can achieve even greater expressivity by extending our framework to tropical polynomials. These polynomials create more flexible decision boundaries while maintaining theoretical guarantees.

\paragraph{Tropical Polynomial Kernel.}
A tropical polynomial in $\trop^d$ takes the form:
\begin{align}
f(x) = \max_{\alpha \in A} (c_\alpha + \langle \alpha, x \rangle)
\end{align}
where $A \subset \mathbb{Z}^d$ is a finite set of integer vectors (monomials), $c_\alpha \in \R$ are coefficients, and $\langle \alpha, x \rangle = \alpha_1 x_1 + \cdots + \alpha_d x_d$.

To fit such polynomials, we use a feature map $\Phi_A: \trop^d \to \trop^{|A|}$ defined by:
\begin{align}
[\Phi_A(x)]_\alpha = \langle \alpha, x \rangle
\end{align}

This feature map transforms the original data into a higher-dimensional space where each coordinate corresponds to a monomial term. A hyperplane in this feature space corresponds to a polynomial in the original space.

\paragraph{Strategic Monomial Selection.}
The choice of monomial set $A$ critically affects both the expressivity and computational complexity of the resulting classifier. We explore two complementary approaches:

\begin{enumerate}
    \item \textbf{Homogeneous Monomials:} We use all monomials of degree $s$, defined as 
    $A_s = \{\alpha \in \mathbb{N}^d : \sum_i \alpha_i = s\}$. The number of such monomials is $\binom{s+d-1}{s}$, which grows polynomially with $s$ for fixed dimension $d$.
    
    \item \textbf{Adaptive Selection:} We sample pairs of points from different classes and construct monomials corresponding to the slopes of separating lines between them. This approach focuses computational resources on the most discriminative monomials.
\end{enumerate}

The degree parameter $s$ controls the trade-off between expressivity and overfitting. Higher degrees create more flexible boundaries but may overfit the training data. Cross-validation can guide this selection process.

Importantly, only a sparse subset of monomials typically becomes active in the final classifier, making the approach computationally efficient even with many candidate monomials.

\paragraph{Classification with Polynomials.}\label{subsec:poly_classification}
To perform classification with polynomials:

\begin{enumerate}
    \item Map the original data to the feature space: $\Phi_A(X^k) = \{\Phi_A(x) : x \in X^k\}$ for each class $k$.
    
    \item Apply the tropical SVM algorithm in this feature space to find apex $a \in \trop^{|A|}$ and spectral radius $\rho(T)$.
    
    \item The classifier in the original space is the polynomial:
    \begin{align}
    f_a(x) = \max_{\alpha \in A} (-a_\alpha + \langle \alpha, x \rangle)
    \end{align}
    
    \item Classify new points by identifying which sector of $f_a(x)$ they fall into.
\end{enumerate}

\paragraph{Margin Guarantees.}
When extending to polynomial classifiers, we maintain theoretical guarantees on the margin. Specifically, when $\rho(T)<0$ (indicating separability in the feature space), the data are separable in the original space with a margin of at least $-\rho(T)/\lVert \Phi_A\rVert_{\text{op},\infty}$, where $\lVert \Phi_A\rVert_{\text{op},\infty}$ is the operator norm of the feature map.

For homogeneous degree-$s$ monomials, this simplifies to $-\rho(T)/s$, meaning the margin scales inversely with the polynomial degree. This gives a principled way to balance expressivity with generalization through the choice of polynomial degree.

This approach maintains the core theoretical guarantees of the hyperplane formulation while substantially increasing model flexibility, as illustrated in Figures~\ref{fig:homogeneous_selection} and \ref{fig:adaptive_polynomial} on the following pages.

\newpage

\vspace*{3em}
\begin{figure}[ht!]
    \centering
    \resizebox{0.7\textwidth}{!}{\clipbox{0.15\width{} 0.30\height{} 0.15\width{} 0.30\height{}}{\input{figures/blobs.pgf}}}
    \caption{Multi-class classification using a cubic polynomial classifier (degree-3 monomials). Each color represents a different class, and the boundaries show where the dominant monomial changes. Note how the polynomial naturally separates the five clusters with piecewise-linear boundaries. The light orange band around the decision boundaries indicates the margin, which maintains a guaranteed lower bound of $-\rho(T)/3$ due to our theoretical results.}
    \label{fig:homogeneous_selection}
\end{figure}
\vspace*{4em}
\begin{figure}[ht!]
    \centering
    \resizebox{0.7\textwidth}{!}{\clipbox{0.15\width{} 0.30\height{} 0.15\width{} 0.30\height{}}{\input{figures/moons-feat-sel.pgf}}}
    \caption{Visualization of a polynomial classifier using the adaptive monomial selection strategy described in Section~\ref{sec:polynomials}. Rather than using all possible monomials, this approach selects terms based on pairs of points from different classes, focusing computational resources on the most discriminative features. The resulting boundary adapts closely to the data's structure while maintaining margin guarantees.}
    \label{fig:adaptive_polynomial}
\end{figure}
\vspace*{3em}


\newpage
\section{Connection to Classical SVMs}\label{sec:maslov}
Tropical hyperplanes can be seen as limits of classical hyperplanes under logarithmic scaling, a process known as Maslov dequantization \cite{viro2001}. This connection suggests a naive approach to tropical SVM: raise the data to a power $\beta > 0$, apply a classical SVM in the transformed space to maximize the margin, then map the result back via a logarithm. As $\beta$ tends to infinity, the resulting decision boundary converges to a tropical hyperplane.

However, this method suffers from severe numerical instability for large $\beta$ and fails to guarantee a good margin in the original space. The limiting hyperplane is typically suboptimal compared to the true classifier obtained through our spectral approach, as illustrated in Figure~\ref{fig:maslov_dequantization}.

\begin{figure}[h]
    \centering
    \resizebox{0.5\textwidth}{!}{\clipbox{0.15\width{} 0.15\height{} 0.15\width{} 0.15\height{}}{\input{figures/log-log.pgf}}}
    \caption{Comparison of hyperplanes obtained through Maslov dequantization and our spectral approach. The limiting hyperplane (red) from dequantization is suboptimal compared to the spectral classifier (black).}
    \label{fig:maslov_dequantization}
\end{figure}

Interestingly, the connection could be exploited in the reverse direction: tropical SVMs may offer efficient, interpretable warm-starts for classical methods, especially in high-dimensional or large-scale settings.

\section{Discussion and Future work}\label{sec:discussion}

We addressed a key computational barrier limiting tropical SVM's practical application in machine learning. By reformulating tropical classification through spectral theory and mean-payoff games, we reduced complexity from exponential to pseudo-polynomial, making tropical SVMs feasible for real-world applications. Our framework provides natural multi-class capabilities, theoretical margin guarantees, and interpretable piecewise-linear decision boundaries.

Our work opens several promising avenues for further investigation. 

\todo[inline]{[Samuel] Future work: relationship between trop poly \& ReLU? Hybrid approaches between tropical \& classical SVMs? Generalization bounds for tropical poly wrt degree? Addressing sentivity to outliers? Parallel, efficient algorithms?}

\subsection*{Acknowledgements}

TBD

\bibliographystyle{plain}
\bibliography{references}

\newpage
\appendix
\section{Proof of Theorem~\ref{thm:spectral_separability} (Spectral Separability)}\label{appendix:proofs}
We provide a complete proof of our main result on spectral separability.

For any Shapley operator $T$, we define its fixed-point set as $\mathcal{S}(T) = \{x \in \trop^d : x \leq T(x)\}$. An important property is that any tropically convex set $V$ verifies $V = S(P_V)$.
Both $P$ and $P^\text{DF}$ have identical fixed-point sets and can serve as the class operators $T^k$ in our framework. We first characterize the maximal possible value for the margin.

\begin{lemma}[Upper bound on margin]\label{lemma:hyperplane_to_operator}
Let $T^k$ be tropical projections on finite point clouds or their diagonal-free equivalents, and $T$ defined as the $\max_2$ of the $T^k$, as in Equation \ref{eq:single_operator}.
If the hyperplane $\mathcal{H}_a$ separates $X^1,\ldots,X^K$ with a margin of at least $\gamma > 0$, then $T(a) \leq -\gamma + a$.
Therefore, if we have an eigenpair $(\rho(T),a)$ of $T$, necessarily $\gamma \le -\rho(T)$.
\end{lemma}

\begin{proof}
Consider two different classes $k$ and $\ell$. Let $I^k$ denote the set of coordinates assigned to class $k$. For any point $x \in X^k$, the margin condition implies
\begin{align}
d_H(x, S^{\ell}) = \max_j(x_j - a_j) - \max_{i \in I^{\ell}}(x_i - a_i) \geq \gamma.
\end{align}

This can be rewritten as: for all $i \in I^{\ell}$,
\begin{align}
x_i - a_i \leq \max_j(x_j - a_j) - \gamma.
\end{align}

Note that $ \max_j(x_j - a_j) = \max_{j\neq i}(x_j - a_j) $ since $\gamma >0$.

Taking the maximum over all $x \in X^k$, we get
\begin{align}
\max_{x \in X^k}(x_i - a_i) \leq \max_{x \in X^k}\left(\max_{j\neq i}(x_j - a_j)\right) - \gamma.
\end{align}

By the definition of $T^k$, this implies
\begin{align}
T^k(a)_i \leq -\gamma + a_i.
\end{align}

Since this holds for all $i \in I^{\ell}$ and all classes $k \neq \ell$, we have $T(a)_i \leq -\gamma + a_i$ for all $i$, which gives us $T(a) \leq -\gamma + a$.
Finally, if $T(a)=\rho(T)+a$, then $\rho(T)\le -\gamma$.
\end{proof}

\begin{lemma}[Max-margin hyperplane]\label{lemma:operator_to_hyperplane}
Let $T^k$ be Shapley operators, and $T$ defined as before. If $\rho(T) < 0$, then there exists a hyperplane $\mathcal{H}_a$ that separates the $\mathcal{S}(T^k)$ with a margin of at least $-\rho(T)$.
\end{lemma}

\begin{proof}
Since $\rho(T) < 0$, there exists $a \in \R^d$ such that $T(a) = \rho(T) + a$. In Algorithm \ref{alg:tropical_svm}, we defined the sectors as
\begin{align}
I^k = \left\{i : T^k(a)_i > \rho(T) + a_i\right\}.
\end{align}

First, we show these sectors are disjoint. If $i \in I^k \cap I^{\ell}$ for $k \neq \ell$, then $T^k(a)_i > \rho(T) + a_i$ and $T^{\ell}(a)_i > \rho(T) + a_i$. But then the second-largest value among $\{T^1(a)_i,\ldots,T^K(a)_i\}$ would exceed $\rho(T) + a_i$, contradicting $T(a)_i = \rho(T) + a_i$.

Next, we show that each point belongs to its assigned sector. For $x \in \mathcal{S}(T^k)$ and $i \not\in I^k$, we have
\begin{align}
x_i \leq T^k(x)_i = (T^k(x) - T^k(a))_i + T^k(a)_i.
\end{align}

Since $T^k$ is non-expansive, $(T^k(x) - T^k(a))_i \leq \max_j(x_j - a_j)$. And since $i \not\in I^k$, we have $T^k(a)_i \leq \rho(T) + a_i$. Combining these,
\begin{align}
x_i - a_i \leq \max_j(x_j - a_j) + \rho(T).
\end{align}

With $\rho(T) < 0$, this implies $x_i - a_i < \max_j(x_j - a_j)$, meaning $i$ cannot be the $\arg\max$ of $x - a$. Therefore, the $\arg\max$ must lie in $I^k$, placing $x$ in its correct sector.

Finally, for the margin, consider $x \in \mathcal{S}(T^k)$ and sector $S^{\ell}$ with $\ell \neq k$. The distance is
\begin{align}
d_H(x, S^{\ell}) = \max_j(x_j - a_j) - \max_{i \in I^{\ell}}(x_i - a_i).
\end{align}

Using the inequalities derived above, we get $d_H(x, S^{\ell}) \geq -\rho(T)$.
\end{proof}

In the binary case where data overlaps, we have $T = \min(T^1, T^2)$, hence $\mathcal{S}(T)$ characterizes the intersection of convex hulls of both point clouds. As shown in \cite{akian2020}, this implies that $\rho(T)$ equals the inner radius of this intersection, measuring the extent of overlap. In the non-separable case, the apex $a$ given by our Algorithm lies exactly at the center of the inner ball of $\mathcal{S}(T^1) \cap \mathcal{S}(T^2)$.

In the multi-class case, the corresponding Shapley operator $T$ can be equivalently expressed as
\begin{align}
T = \max_{1 \leq k < l \leq n}\min(T^k, T^l).
\end{align}
Intuitively, this can be thought of as representing the union of pairwise intersections between data classes, although the $\max$ operator does not strictly correspond to a union of fixed-point sets. This formulation provides an intuition on why our operator effectively characterizes separability across multiple classes.

\begin{figure}[htbp]
    \centering
    \resizebox{0.5\textwidth}{!}{\clipbox{0.15\width{} 0.15\height{} 0.15\width{} 0.15\height{}}{\input{figures/non-separable.pgf}}}
    \caption{Non-separable case: $\rho(T) \geq 0$, indicating class overlap. The spectral radius quantifies the minimum perturbation required to achieve separability, and the inner radius of the convex hulls' intersection.}
    \label{fig:non_separable}
\end{figure}


\begin{lemma}[Overlap interpretation]\label{lemma:perturbation}
Let $T^k$ be the diagonal-free projections. For binary classification with $\rho(T) \geq 0$, there exists a perturbation of the point sets $X^1$ and $X^2$, with each point moved by at most $\rho(T)$ in the tropical metric, such that the tropical convex hulls of the perturbed sets have empty intersection.
\end{lemma}

\begin{proof}
Let $a$ be the eigenvector corresponding to $\rho(T)$, i.e., $T(a) = \rho(T) + a$. Let $\mathcal{H}_a$ be the tropical hyperplane with apex $a$. We construct a perturbation by projecting onto $\mathcal{H}_a$ any point whose distance to $\mathcal{H}_a$ is less than $\rho(T)$.

For a point $x \in \trop^d$, its distance to $\mathcal{H}_a$ is
\begin{align}
d_H(x, \mathcal{H}_a) = \max_i(x_i - a_i) - \max_2(x_i - a_i),
\end{align}
where $\max_2$ denotes the second-largest value.

For each point $x_j \in X^1 \cup X^2$, we define a perturbed point $\tilde{x}_j$ as follows:
\begin{itemize}
\item If $d_H(x_j, \mathcal{H}_a) \geq \rho(T)$, then $\tilde{x}_j = x_j$ (no perturbation)
\item If $d_H(x_j, \mathcal{H}_a) < \rho(T)$, let $s = \arg\max_i(x_{ji} - a_i)$ be the sector of $x_j$. We set:
  \begin{align}
  \tilde{x}_{ji} = \begin{cases}
  x_{ji} - d_H(x_j, \mathcal{H}_a) & \text{if } i = s \\
  x_{ji} & \text{otherwise}
  \end{cases}
  \end{align}
\end{itemize}

This projection ensures that $\tilde{x}_j$ lies exactly on $\mathcal{H}_a$.

Therefore, for any $x^{c}$ in the tropical convex hull of class $c\in\{1,2\}$,
\begin{equation}
[x^{c}]_{i}\le T^{c}(x^{c})_{i}=\underbrace{\left(T^{c}(x^{c})-T^{c}(a)\right)_{i}}_{\le\,\max_{k\ne i}(x_{k}^{c}-a_{k})}+T^{c}(a)_{i}.\label{eq:major}
\end{equation}
Fix a coordinate $i$. If $x\in X^{1}\cup X^{2}$ is in sector $s\ne i$, and reaches it second argmax at coordinate $t$, then for $k\ne s$, by definition,
$(\tilde{x}_{j}-a)_{k}\le(x_{j}-a)_{t}\le(\tilde{x}_{j}-a)_{s}$,
hence $\tilde{x}_{jk}-\max_{k\ne i}(\tilde{x}_{jk}-a_{k})\le a_{i}$.
Otherwise, $x_{j}$ is in the $i$-th sector and $\max_{k\ne i}(\tilde{x}_{jk}-a_{k})=x_{jt}-a_{t}$,
thus
\[
\tilde{x}_{ji}-\max_{k\ne i}(\tilde{x}_{j}-a)_{k}=(\tilde{x}_{j}-a)_{i}-(\tilde{x}_{j}-a)_{t}+a_{i}\ge a_{i},
\]
with equality if $d_{H}\left(x_{j},\mathcal{H}_{a}\right)\le\rho(T)$.

Suppose by symmetry that $T(a)_{i}=T^{1}(a)_{i}=\rho(T)+a_{i}$. We
also have $T^{2}(a)\ge\rho(T)+a_{i}$. Then, using the proof of Theorem
22 in \cite{akian2020}, there exists witness points $x_{j_{1}}\in X^{1}$ and
$x_{j_{2}}\in X^{2}$ in sector $i$ , with $x_{j_{1}}$ being at
distance $\rho(T)$ from $\mathcal{H}_{a}$ and $x_{j_{2}}$ at distance
greater than $\rho(T)$. Therefore, $\tilde{x}_{j_{1}i}-\max_{k\ne i}(\tilde{x}_{j_{1}k}-a_{k})=a_{i}$
and $\tilde{x}_{j_{2}i}-\max_{k\ne i}(\tilde{x}_{j_{2}k}-a_{k})\ge a_{i}$.
Moreover, for any $j$ such that $x_{j}\in X^1$ is in sector $i$,
Equation \ref{eq:major} gives $d_{H}(x_{j},\mathcal{H}_{a})\le\rho(T)$.

Let $\tilde{T}^{1}$ and $\tilde{T}^{2}$ be the diagonal-free projections
over transformed projections, and $\tilde{T}=\min(\tilde{T}^{1},\tilde{T}^{2})$.
We have just shown that $\tilde{T}(a)_{i}=\tilde{T}^{1}(a)_{i}=a_{i}$,
and finally $\tilde{T}(a)=a$.
\end{proof}

We summarize the proof of the Main Theorem, which holds when $T^k$ are diagonal-free projections:

\begin{proof}[Proof of Theorem~\ref{thm:spectral_separability}]
For part 1 (Separability Criterion): If we have an eigenpair $(\rho(T),a)$ such that the data are separable with margin $\gamma > 0$, then by Lemma~\ref{lemma:hyperplane_to_operator}, $\rho(T) \leq -\gamma < 0$. Conversely, if $\rho(T) < 0$, then by Lemma~\ref{lemma:operator_to_hyperplane}, the data are separable.

For part 2 (Margin Optimality): Lemma~\ref{lemma:hyperplane_to_operator} shows that no hyperplane can achieve a margin larger than $-\rho(T)$, while Lemma~\ref{lemma:operator_to_hyperplane} provides a construction achieving exactly this margin.

For part 3 (Soft-Margin Interpretation): Lemma~\ref{lemma:perturbation} shows that in the binary case, $\rho(T)$ is positive and characterizes the overlap between the tropical convex hulls.
\end{proof}

\section{Empirical Evaluation}\label{appendix:empirical}

To validate our theoretical complexity analysis, we evaluated both standard tropical SVM and an enhanced tropical polynomial implementation (with $k=4$ sampling points per class) against scikit-learn's LinearSVC on benchmark datasets \cite{scikit-learn,waveform_database_generator_(version_1)_107}. All experiments used 5-fold cross-validation with standardized features. We compare training times for a fixed convergence threshold. All experiments were conducted on a MacBook Air M2 with 16GB RAM using NumPy \cite{harris2020array}.

\begin{table}[h]
\centering
\footnotesize
\begin{tabular}{@{}l@{\hskip 4pt}c@{\hskip 4pt}c@{\hskip 8pt}cc@{\hskip 4pt}c@{\hskip 8pt}ccc@{\hskip 8pt}cc@{}}
\toprule
\multirow{3}{*}{\textbf{Dataset}} & \multirow{3}{*}{\textbf{\#C}} & \multirow{3}{*}{\textbf{\#S}} & \multicolumn{8}{c}{\textbf{Accuracy (\%) / Training Time (s) / \#KM Iter}} \\
\cmidrule(lr){4-11}
& & & \multicolumn{3}{c}{\textbf{Tropical SVM}} & \multicolumn{3}{c}{\textbf{Tropical Poly}} & \multicolumn{2}{c}{\textbf{Linear SVC}} \\
\cmidrule(lr){4-6} \cmidrule(lr){7-9} \cmidrule(lr){10-11}
& & & Acc & Time & \#KM & Acc & Time & \#KM & Acc & Time \\
\midrule
Iris & 3 & 150 & 66.7 & 0.0006 & 11.2 & 94.0 & 0.102 & 108.6 & 92.7 & 0.0004 \\
Wine & 3 & 178 & 74.2 & 0.0019 & 25.0 & 93.3 & 0.115 & 113.6 & 97.8 & 0.0006 \\
Breast Cancer & 2 & 569 & 82.1 & 0.0081 & 32.6 & 91.7 & 0.596 & 432.6 & 96.7 & 0.0008 \\
Waveform & 3 & 5000 & 49.9 & 0.0756 & 23.0 & 64.4 & 9.330 & 319.8 & 86.7 & 0.0246 \\
\bottomrule
\end{tabular}
\vspace{0.5em}
\caption{Performance comparison across benchmark datasets (5-fold cross-validation). Accuracy standard deviations range from 1.7\% to 9.1\%. \#C: number of classes; \#S: number of samples; \#KM: average number of Krasnoselskii-Mann iterations.
Chosen convergence threshold $\varepsilon$ is $10^{-3}$ times the the characteristic variation scale of the considered data.}
\label{tab:benchmark_results}
\end{table}    

The standard tropical SVM implementation exhibits training times close to LinearSVC on smaller datasets, demonstrating practical computational feasibility. The tropical polynomial variant requires additional computation but substantially improves accuracy, approaching LinearSVC on datasets like Iris.
Tropical SVM indeed fails to seprarate these datasets and thus performs poorly, while polynomials make the data separable.

Notably, the spectral radius values closely align with our theoretical predictions: datasets yielding negative spectral radius values (Wine: -7.53, Breast Cancer: -1.76, Iris: -0.97) exhibited the highest tropical polynomial accuracy, while the non-separable Waveform dataset (spectral radius: 0.87) proved more challenging.

As expected, the number of monomials increases from $d+1$ in standard tropical SVM to $O(d^k)$ in the polynomial variant, explaining the observed computation-accuracy tradeoff. While specialized classical SVM implementations remain faster, our results conclusively demonstrate that tropical SVMs can be practically computed with pseudo-polynomial guarantees.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.48\textwidth}
        \centering
        \resizebox{0.95\textwidth}{!}{\input{figures/pca_degree_scaling.pgf}}
        \caption{Training time vs. number of monomials}
        \label{fig:pca_degree_scaling}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\textwidth}
        \centering
        \resizebox{0.95\textwidth}{!}{\input{figures/sample_size_scaling.pgf}}
        \caption{Training time vs. size of training set}
        \label{fig:sample_size_scaling}
    \end{subfigure}
    \caption{Performance scaling analysis of tropical SVM on MNIST data}
    \label{fig:scaling_analysis}
\end{figure}

Figure~\ref{fig:scaling_analysis} reveals that the tropical SVM algorithm exhibits linear scaling behavior both with respect to the number of effective monomials and the training set size. We used a Python script that systematically varies PCA dimensions, polynomial degrees, and sample sizes on MNIST data \cite{MNIST}.

\todo{Fix algorithm. Regen figures and tables. Add KM iterations vs. $1/\varepsilon$.}

\newpage
\section*{NeurIPS Paper Checklist}

\begin{enumerate}

\item {\bf Claims}
    \item[] Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?
    \item[] Answer: \answerYes{}
    \item[] Justification: The abstract and introduction clearly state the contributions—including the spectral characterization, margin optimality, pseudo‐polynomial algorithm, and extension to tropical polynomials—which are supported by both theoretical results and empirical evaluations.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the abstract and introduction do not include the claims made in the paper.
        \item The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. 
        \item The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. 
        \item It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. 
    \end{itemize}

\item {\bf Limitations}
    \item[] Question: Does the paper discuss the limitations of the work performed by the authors?
    \item[] Answer: \answerYes{}
    \item[] Justification: The paper explicitly discusses limitations such as sensitivity to outliers and the challenge of incorporating soft margins (see the ``Limitations'' paragraph in Section~\ref{sec:spectral})
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. 
        \item The authors are encouraged to create a separate "Limitations" section in their paper.
        \item The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.
        \item The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.
        \item The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.
        \item The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.
        \item If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.
        \item While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
    \end{itemize}

\item {\bf Theory Assumptions and Proofs}
    \item[] Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?
    \item[] Answer: \answerYes{}
    \item[] Justification: All major theoretical results—including the spectral separability theorem—are supported by clearly stated assumptions and complete proofs provided in the Appendix~\ref{appendix:proofs}.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not include theoretical results. 
        \item All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
        \item All assumptions should be clearly stated or referenced in the statement of any theorems.
        \item The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. 
        \item Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
        \item Theorems and Lemmas that the proof relies upon should be properly referenced. 
    \end{itemize}

    \item {\bf Experimental Result Reproducibility}
    \item[] Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?
    \item[] Answer: \answerYes{}
    \item[] Justification: The algorithm is fully described in Section~\ref{sec:algorithm}. The experimental section provides details on data splits (5-fold cross-validation), training times, accuracy metrics, and references a publicly available GitHub repository for code and reproduction (see Table~\ref{tab:benchmark_results} and Appendix~\ref{appendix:empirical}).
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not include experiments.
        \item If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
        \item If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. 
        \item Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
        \item While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example
        \begin{enumerate}
            \item If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.
            \item If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.
            \item If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).
            \item We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
        \end{enumerate}
    \end{itemize}


\item {\bf Open access to data and code}
    \item[] Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?
    \item[] Answer: \answerYes{}
    \item[] Justification: The paper includes a link to a GitHub repository (\url{https://github.com/samuelbx/tropical-svm}) with code and instructions for reproducing the experiments.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that paper does not include experiments requiring code.
        \item Please see the NeurIPS code and data submission guidelines (\url{https://nips.cc/public/guides/CodeSubmissionPolicy}) for more details.
        \item While we encourage the release of code and data, we understand that this might not be possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
        \item The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (\url{https://nips.cc/public/guides/CodeSubmissionPolicy}) for more details.
        \item The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
        \item The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
        \item At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
        \item Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
    \end{itemize}


\item {\bf Experimental Setting/Details}
    \item[] Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?
    \item[] Answer: \answerYes{}
    \item[] Justification: The paper details the experimental setup, including the use of 5-fold cross-validation, data standardization, and provides training times and accuracy metrics in Table~\ref{tab:benchmark_results} and related figures in the appendix.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not include experiments.
        \item The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
        \item The full details can be provided either with the code, in appendix, or as supplemental material.
    \end{itemize}

\item {\bf Experiment Statistical Significance}
    \item[] Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?
    \item[] Answer: \answerYes{}
    \item[] Justification: The results are reported with standard deviations.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not include experiments.
        \item The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
        \item The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
        \item The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
        \item The assumptions made should be given (e.g., Normally distributed errors).
        \item It should be clear whether the error bar is the standard deviation or the standard error of the mean.
        \item It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96\% CI, if the hypothesis of Normality of errors is not verified.
        \item For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
        \item If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
    \end{itemize}

\item {\bf Experiments Compute Resources}
    \item[] Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?
    \item[] Answer: \answerYes{}
    \item[] Justification: All experiments were conducted on a MacBook Air M2. These specifications are typical for small-scale benchmark experiments, and the reported training times reflect the performance on this hardware.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not include experiments.
        \item The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.
        \item The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. 
        \item The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). 
    \end{itemize}
    
\item {\bf Code Of Ethics}
    \item[] Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics \url{https://neurips.cc/public/EthicsGuidelines}?
    \item[] Answer: \answerYes{}
    \item[] Justification: The work is theoretical and algorithmic with supporting experiments on standard benchmark datasets; there are no ethical issues or concerns related to the research.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
        \item If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.
        \item The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
    \end{itemize}


\item {\bf Broader Impacts}
    \item[] Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?
    \item[] Answer: \answerNA{}
    \item[] Justification: The research is primarily theoretical and methodological with no direct societal impact, and no discussion of broader impacts is necessary.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that there is no societal impact of the work performed.
        \item If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
        \item Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
        \item The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
        \item The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
        \item If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
    \end{itemize}
    
\item {\bf Safeguards}
    \item[] Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)?
    \item[] Answer: \answerNA{}
    \item[] Justification: The work does not involve the release of data or models that present a high risk of misuse.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper poses no such risks.
        \item Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. 
        \item Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
        \item We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
    \end{itemize}

\item {\bf Licenses for existing assets}
    \item[] Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?
    \item[] Answer: \answerYes{}.
    \item[] Justification: All referenced works and datasets are properly cited, and the GitHub repository is expected to include license information consistent with proper academic practice.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not use existing assets.
        \item The authors should cite the original paper that produced the code package or dataset.
        \item The authors should state which version of the asset is used and, if possible, include a URL.
        \item The name of the license (e.g., CC-BY 4.0) should be included for each asset.
        \item For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
        \item If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, \url{paperswithcode.com/datasets} has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
        \item For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
        \item If this information is not available online, the authors are encouraged to reach out to the asset's creators.
    \end{itemize}

\item {\bf New Assets}
    \item[] Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?
    \item[] Answer: \answerYes{}
    \item[] Justification: The paper introduces a novel algorithm and provides experimental code, with documentation available in the supplementary GitHub repository.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not release new assets.
        \item Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. 
        \item The paper should discuss whether and how consent was obtained from people whose asset is used.
        \item At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
    \end{itemize}

\item {\bf Crowdsourcing and Research with Human Subjects}
    \item[] Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? 
    \item[] Answer: \answerNA{}
    \item[] Justification: The work does not involve crowdsourcing or human subjects.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
        \item Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. 
        \item According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. 
    \end{itemize}

\item {\bf Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects}
    \item[] Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?
    \item[] Answer: \answerNA{}
    \item[] Justification: The research does not involve human subjects, so IRB approval is not applicable.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
        \item Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. 
        \item We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. 
        \item For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.
    \end{itemize}

\end{enumerate}

\end{document}
