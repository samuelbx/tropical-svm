\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{vapnik1999}
\citation{scholkopf2002}
\citation{maclagan2015}
\citation{zhang2018}
\citation{zhang2018,montufar}
\citation{maragos2020,akian2020}
\citation{yoshida2019}
\citation{maragos2021}
\citation{gartner2008}
\citation{shapley1953}
\citation{gillette1957}
\citation{zwick1996}
\citation{kolokoltsov1997,gaubert2004}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Motivation: Beyond Linear Boundaries.}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Tropical SVMs.}{1}{section.1}\protected@file@percent }
\citation{cohen2004}
\citation{AGNS10}
\citation{gaubert2011}
\citation{CuninghameGreen2003}
\citation{akiangaubertqisaadi}
\citation{Charisopoulos2017}
\citation{maragos2021}
\citation{zhang2018}
\citation{yoshida2019}
\citation{monod2022}
\citation{tang2020,Yoshida2023}
\citation{scikit-learn}
\citation{scikit-learn}
\@writefile{toc}{\contentsline {paragraph}{Background on Mean‚ÄêPayoff Games.}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Contributions.}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Related Work.}{2}{Item.4}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{orange}{}{orange!20}{\leavevmode {\color  {orange!20}o}}\ quote lavishly yoshida}{2}{section*.2}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{17655632}{13492332}
\pgfsyspdfmark {pgfid4}{35988437}{13420470}
\pgfsyspdfmark {pgfid5}{38101972}{13271149}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{orange}{}{orange!20}{\leavevmode {\color  {orange!20}o}}\ SG: I will add references to AGG, Sergei, YangQi, Joswig (transport optimal tropical), Yue Ren/Montufar. Discuss Yoshida/heuristics more precisely; Paragos }{2}{section*.3}\protected@file@percent }
\pgfsyspdfmark {pgfid6}{20112833}{12020356}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{orange}{}{red}{\leavevmode {\color  {red}o}}\ SG: in Figure \ref  {fig:tropical_poly}, is $(-0.65, 0.58, 0.07)$ the apex or the oposite of the apex. apex = sommet. it seems to be the sommet. We need to decide whether the apex is $a$ or $-a$ and check consistency in the separating hyperplanes}{2}{section*.5}\protected@file@percent }
\pgfsyspdfmark {pgfid9}{20112833}{10138596}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{orange}{}{orange!20}{\leavevmode {\color  {orange!20}o}}\ SG: add bibliographic reference to moons?}{2}{section*.6}\protected@file@percent }
\pgfsyspdfmark {pgfid10}{7104430}{9623632}
\pgfsyspdfmark {pgfid13}{35988437}{9551770}
\pgfsyspdfmark {pgfid14}{38101972}{9402449}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Left: Tropical hyperplane represented in projective space, with the constant vector $(1, 1, 1)$ projected to the origin. Each sector corresponds to a coordinate that dominates relative to the apex, here equal to $(-0.65, 0.58, 0.07)$ and located at the elbow. The two lower sectors are merged and assigned to orange points. Margin is optimal and is represented in yellow. Right: Visualization of a degree-2 polynomial classifier on a toy dataset \cite  {scikit-learn}. Each region corresponds to a sector where a specific affine combination of the features dominates, creating an interpretable piecewise-linear decision boundary.\relax }}{3}{figure.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:tropical_poly}{{1}{3}{Left: Tropical hyperplane represented in projective space, with the constant vector $(1, 1, 1)$ projected to the origin. Each sector corresponds to a coordinate that dominates relative to the apex, here equal to $(-0.65, 0.58, 0.07)$ and located at the elbow. The two lower sectors are merged and assigned to orange points. Margin is optimal and is represented in yellow. Right: Visualization of a degree-2 polynomial classifier on a toy dataset \cite {scikit-learn}. Each region corresponds to a sector where a specific affine combination of the features dominates, creating an interpretable piecewise-linear decision boundary.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Tropical Geometry Preliminaries}{3}{section.2}\protected@file@percent }
\newlabel{sec:prelim}{{2}{3}{Tropical Geometry Preliminaries}{section.2}{}}
\@writefile{toc}{\contentsline {paragraph}{The Max-Plus Semiring.}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Projective Space.}{3}{equation.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Hyperplanes and Sectors.}{3}{equation.2.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{orange}{}{orange!20}{\leavevmode {\color  {orange!20}o}}\ the apex is usually $-a$ and this is defined only for $a\in \mathbb  {R}^n$, $a$ is rather a vector of parameters}{3}{section*.7}\protected@file@percent }
\pgfsyspdfmark {pgfid15}{32479719}{11337782}
\pgfsyspdfmark {pgfid18}{35988437}{11265920}
\pgfsyspdfmark {pgfid19}{38101972}{11116599}
\citation{cohen2004}
\citation{cohen2004,develin2004}
\citation{AGNS10}
\citation{akiangaubertqisaadi}
\citation{akiangaubertqisaadi}
\citation{AGGut10}
\citation{kolokoltsov1992}
\citation{akian_correspondence_2011}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{orange}{}{red!30}{\leavevmode {\color  {red!30}o}}\ SG: New/consistent terminology}{4}{section*.8}\protected@file@percent }
\pgfsyspdfmark {pgfid20}{20112833}{44964539}
\@writefile{toc}{\contentsline {paragraph}{Hilbert Seminorm.}{4}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Convexity and Projections.}{4}{equation.2.5}\protected@file@percent }
\newlabel{e-canonical}{{7}{4}{Convexity and Projections}{equation.2.7}{}}
\newlabel{e-def-DF}{{8}{4}{Convexity and Projections}{equation.2.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Spectral Framework for Tropical SVMs}{4}{section.3}\protected@file@percent }
\newlabel{sec:spectral}{{3}{4}{Spectral Framework for Tropical SVMs}{section.3}{}}
\citation{nussbaum1986,AGGut10,akiangaubertqisaadi}
\citation{gartner2008}
\@writefile{toc}{\contentsline {paragraph}{Shapley Operators and Their Spectral Theory.}{5}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Constructing the Classification Operator.}{5}{equation.3.9}\protected@file@percent }
\newlabel{eq:single_operator}{{10}{5}{Constructing the Classification Operator}{equation.3.10}{}}
\@writefile{toc}{\contentsline {paragraph}{Main Theorem: Spectral Radius and Margin.}{5}{equation.3.10}\protected@file@percent }
\newlabel{thm:spectral_separability}{{1}{5}{}{theorem.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Benefits of the Spectral Approach.}{5}{theorem.1}\protected@file@percent }
\citation{akianmfcs}
\citation{akianmfcs}
\citation{akianmfcs}
\citation{baillonbruck}
\citation{akianmfcs}
\@writefile{toc}{\contentsline {paragraph}{Limitations.}{6}{theorem.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Algorithm and Implementation}{6}{section.4}\protected@file@percent }
\newlabel{sec:algorithm}{{4}{6}{Algorithm and Implementation}{section.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Computing the Spectral Radius with Krasnoselskii--Mann Iterations.}{6}{section.4}\protected@file@percent }
\newlabel{subsec:spectral_computation}{{4}{6}{Computing the Spectral Radius with Krasnoselskii--Mann Iterations}{section.4}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Krasnoselskii--Mann Iteration with damping\nobreakspace  {}\cite  {akianmfcs}\relax }}{6}{algorithm.1}\protected@file@percent }
\newlabel{alg:km_iteration}{{1}{6}{Krasnoselskii--Mann Iteration with damping~\cite {akianmfcs}\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {paragraph}{The Tropical SVM Algorithm.}{6}{ALC@unique.7}\protected@file@percent }
\newlabel{subsec:complete_algorithm}{{4}{6}{The Tropical SVM Algorithm}{ALC@unique.7}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Tropical SVM\relax }}{6}{algorithm.2}\protected@file@percent }
\newlabel{alg:tropical_svm}{{2}{6}{Tropical SVM\relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Proof of Concept.}{7}{ALC@unique.20}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Tropical Polynomials for Enhanced Expressivity}{7}{section.5}\protected@file@percent }
\newlabel{sec:polynomials}{{5}{7}{Tropical Polynomials for Enhanced Expressivity}{section.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Tropical Polynomial Kernel.}{7}{section.5}\protected@file@percent }
\newlabel{e-def-feature}{{12}{7}{Tropical Polynomial Kernel}{equation.5.12}{}}
\@writefile{toc}{\contentsline {paragraph}{Strategic Monomial Selection.}{7}{equation.5.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Classification with Polynomials.}{7}{Item.8}\protected@file@percent }
\newlabel{subsec:poly_classification}{{5}{7}{Classification with Polynomials}{Item.8}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{orange}{}{red!30}{\leavevmode {\color  {red!30}o}}\ SG: is it $a$ or $-a$, inconsistency}{8}{section*.9}\protected@file@percent }
\pgfsyspdfmark {pgfid21}{20112833}{45332518}
\@writefile{toc}{\contentsline {paragraph}{Margin Guarantees.}{8}{section*.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Multi-class classification using a cubic polynomial classifier (degree-3 monomials). Each color represents a different class, and the boundaries show where the dominant monomial changes. Note how the polynomial naturally separates the five clusters with piecewise-linear boundaries. The light orange band around the decision boundaries indicates a lower bound on the margin, equal to $-\rho (T)/3$, as explained in the last paragraph of Section\nobreakspace  {}\ref  {sec:polynomials}.\relax }}{9}{figure.caption.10}\protected@file@percent }
\newlabel{fig:homogeneous_selection}{{2}{9}{Multi-class classification using a cubic polynomial classifier (degree-3 monomials). Each color represents a different class, and the boundaries show where the dominant monomial changes. Note how the polynomial naturally separates the five clusters with piecewise-linear boundaries. The light orange band around the decision boundaries indicates a lower bound on the margin, equal to $-\rho (T)/3$, as explained in the last paragraph of Section~\ref {sec:polynomials}.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Visualization of a polynomial classifier using the adaptive monomial selection strategy described in Section\nobreakspace  {}\ref  {sec:polynomials}. Rather than using all possible monomials, this approach selects terms based on pairs of points from different classes, focusing computational resources on the most discriminative features. The resulting boundary adapts closely to the data's structure while maintaining margin guarantees.\relax }}{9}{figure.caption.11}\protected@file@percent }
\newlabel{fig:adaptive_polynomial}{{3}{9}{Visualization of a polynomial classifier using the adaptive monomial selection strategy described in Section~\ref {sec:polynomials}. Rather than using all possible monomials, this approach selects terms based on pairs of points from different classes, focusing computational resources on the most discriminative features. The resulting boundary adapts closely to the data's structure while maintaining margin guarantees.\relax }{figure.caption.11}{}}
\citation{viro2001}
\bibstyle{unsrt}
\bibdata{references}
\@writefile{toc}{\contentsline {section}{\numberline {6}Connection to Classical SVMs}{10}{section.6}\protected@file@percent }
\newlabel{sec:maslov}{{6}{10}{Connection to Classical SVMs}{section.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparison of hyperplanes obtained through Maslov dequantization and our spectral approach. The limiting hyperplane (red) from dequantization is suboptimal compared to the spectral classifier (black).\relax }}{10}{figure.caption.12}\protected@file@percent }
\newlabel{fig:maslov_dequantization}{{4}{10}{Comparison of hyperplanes obtained through Maslov dequantization and our spectral approach. The limiting hyperplane (red) from dequantization is suboptimal compared to the spectral classifier (black).\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion and Future work}{10}{section.7}\protected@file@percent }
\newlabel{sec:discussion}{{7}{10}{Discussion and Future work}{section.7}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{orange}{}{orange!20}{\leavevmode {\color  {orange!20}o}}\ SG: ref to chaloupka}{10}{section*.13}\protected@file@percent }
\pgfsyspdfmark {pgfid25}{33154006}{8712514}
\pgfsyspdfmark {pgfid28}{35988437}{8640652}
\pgfsyspdfmark {pgfid29}{38101972}{8491331}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{orange}{}{red!30}{\leavevmode {\color  {red!30}o}}\ Remercier les eleves de l'an dernier}{10}{section*.14}\protected@file@percent }
\pgfsyspdfmark {pgfid30}{20112833}{5146406}
\bibcite{vapnik1999}{{1}{}{{}}{{}}}
\bibcite{scholkopf2002}{{2}{}{{}}{{}}}
\bibcite{maclagan2015}{{3}{}{{}}{{}}}
\bibcite{zhang2018}{{4}{}{{}}{{}}}
\bibcite{montufar}{{5}{}{{}}{{}}}
\bibcite{maragos2020}{{6}{}{{}}{{}}}
\bibcite{akian2020}{{7}{}{{}}{{}}}
\bibcite{yoshida2019}{{8}{}{{}}{{}}}
\bibcite{maragos2021}{{9}{}{{}}{{}}}
\bibcite{gartner2008}{{10}{}{{}}{{}}}
\bibcite{shapley1953}{{11}{}{{}}{{}}}
\bibcite{gillette1957}{{12}{}{{}}{{}}}
\bibcite{zwick1996}{{13}{}{{}}{{}}}
\bibcite{kolokoltsov1997}{{14}{}{{}}{{}}}
\bibcite{gaubert2004}{{15}{}{{}}{{}}}
\bibcite{cohen2004}{{16}{}{{}}{{}}}
\bibcite{AGNS10}{{17}{}{{}}{{}}}
\bibcite{gaubert2011}{{18}{}{{}}{{}}}
\bibcite{CuninghameGreen2003}{{19}{}{{}}{{}}}
\bibcite{akiangaubertqisaadi}{{20}{}{{}}{{}}}
\bibcite{Charisopoulos2017}{{21}{}{{}}{{}}}
\bibcite{monod2022}{{22}{}{{}}{{}}}
\bibcite{tang2020}{{23}{}{{}}{{}}}
\bibcite{Yoshida2023}{{24}{}{{}}{{}}}
\bibcite{scikit-learn}{{25}{}{{}}{{}}}
\bibcite{develin2004}{{26}{}{{}}{{}}}
\bibcite{AGGut10}{{27}{}{{}}{{}}}
\bibcite{kolokoltsov1992}{{28}{}{{}}{{}}}
\bibcite{akian_correspondence_2011}{{29}{}{{}}{{}}}
\bibcite{nussbaum1986}{{30}{}{{}}{{}}}
\bibcite{akianmfcs}{{31}{}{{}}{{}}}
\bibcite{baillonbruck}{{32}{}{{}}{{}}}
\bibcite{viro2001}{{33}{}{{}}{{}}}
\bibcite{harris2020array}{{34}{}{{}}{{}}}
\bibcite{MNIST}{{35}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Proof of Theorem\nobreakspace  {}\ref  {thm:spectral_separability} (Spectral Separability)}{13}{appendix.A}\protected@file@percent }
\newlabel{appendix:proofs}{{A}{13}{Proof of Theorem~\ref {thm:spectral_separability} (Spectral Separability)}{appendix.A}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{orange}{}{red!30}{\leavevmode {\color  {red!30}o}}\ SG Both $P$ and $P^\text  {DF}$ have identical fixed-point sets -- not sure}{13}{section*.15}\protected@file@percent }
\pgfsyspdfmark {pgfid31}{20112833}{42242946}
\newlabel{lemma:hyperplane_to_operator}{{2}{13}{Upper bound on margin}{theorem.2}{}}
\newlabel{lemma:operator_to_hyperplane}{{3}{13}{Max-margin hyperplane}{theorem.3}{}}
\citation{akian2020}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Non-separable case: $\rho (T) \geqslant 0$, indicating class overlap. The spectral radius quantifies the minimum perturbation required to achieve separability, and the inner radius of the convex hulls' intersection.\relax }}{14}{figure.caption.16}\protected@file@percent }
\newlabel{fig:non_separable}{{5}{14}{Non-separable case: $\rho (T) \geq 0$, indicating class overlap. The spectral radius quantifies the minimum perturbation required to achieve separability, and the inner radius of the convex hulls' intersection.\relax }{figure.caption.16}{}}
\newlabel{lemma:perturbation}{{4}{14}{Overlap interpretation}{theorem.4}{}}
\citation{akian2020}
\citation{scikit-learn}
\citation{harris2020array}
\citation{MNIST}
\citation{MNIST}
\newlabel{eq:major}{{25}{15}{Proof of Theorem~\ref {thm:spectral_separability} (Spectral Separability)}{equation.A.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Proof of Concept}{15}{appendix.B}\protected@file@percent }
\newlabel{appendix:empirical}{{B}{15}{Proof of Concept}{appendix.B}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Performance comparison across benchmark datasets (5-fold cross-validation). Accuracy standard deviations range from 1.1\% to 9.7\%. \#C: number of classes; \#S: number of samples; \#KM: average number of Krasnoselskii--Mann iterations; $\rho (T)$: spectral radius. Convergence threshold $\varepsilon = 10^{-12}$.\relax }}{16}{table.caption.17}\protected@file@percent }
\newlabel{tab:benchmark_results}{{1}{16}{Performance comparison across benchmark datasets (5-fold cross-validation). Accuracy standard deviations range from 1.1\% to 9.7\%. \#C: number of classes; \#S: number of samples; \#KM: average number of Krasnoselskii--Mann iterations; $\rho (T)$: spectral radius. Convergence threshold $\varepsilon = 10^{-12}$.\relax }{table.caption.17}{}}
\newlabel{fig:pca_degree_scaling}{{6a}{16}{Training time vs. number of monomials\relax }{figure.caption.18}{}}
\newlabel{sub@fig:pca_degree_scaling}{{a}{16}{Training time vs. number of monomials\relax }{figure.caption.18}{}}
\newlabel{fig:sample_size_scaling}{{6b}{16}{Training time vs. size of training set\relax }{figure.caption.18}{}}
\newlabel{sub@fig:sample_size_scaling}{{b}{16}{Training time vs. size of training set\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Performance scaling analysis of tropical SVM on MNIST data \cite  {MNIST}.\relax }}{16}{figure.caption.18}\protected@file@percent }
\newlabel{fig:scaling_analysis}{{6}{16}{Performance scaling analysis of tropical SVM on MNIST data \cite {MNIST}.\relax }{figure.caption.18}{}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\gdef \@abspage@last{22}
